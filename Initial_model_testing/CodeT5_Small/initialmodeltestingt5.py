# -*- coding: utf-8 -*-
"""InitialModelTestingT5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EtvPvRDUvME6pGX0jStFOfwR-N6JR0MJ
"""

!pip install transformers datasets

import json
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

file_path = "/content/Testing_dataset_simple.jsonl"

with open(file_path, 'r') as f:
    data = [json.loads(line) for line in f]

print("Example Question:")
print(data[0]["question"])

instruction = "Convert this word problem into Python code to calculate the answer:"
for item in data:
    item["question"] = f"{instruction} {item['question']}"

print("Example Question with Instruction:")
print(data[0]["question"])

model_name = "Salesforce/codet5-small"  #switch between models
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def generate_code(question, model, tokenizer, max_length=100):

    inputs = tokenizer(question, return_tensors="pt")

    outputs = model.generate(inputs["input_ids"], max_length=max_length)

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

question = data[0]["question"]
generated_code = generate_code(question, model, tokenizer)
print("Question:", question)
print("Generated Code:", generated_code)

for item in data[:10]:  #Limits to the first 5 questions
    question = item["question"]
    print("Question:", question)
    generated_code = generate_code(question, model, tokenizer)
    print("Generated Code:", generated_code)
    print("-" * 50)